import os
import json
import asyncio
import requests
import html
import re
import logging
from datetime import datetime, timedelta, timezone
from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from groq import Groq

# ============ LOGGING ============

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler('scout_radar.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============ CONFIG ============

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TARGET_CHANNEL_ID = os.getenv("CHANNEL_ID")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

STATE_FILE = "scout_history.json"

MAX_AGE_DAYS = 3
MAX_POSTS_PER_RUN = 100
GROQ_DELAY = 2
MESSAGE_DELAY = 3
MIN_STARS = 0
MIN_API_CALLS_REMAINING = 50

API_HEADERS = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

bot = Bot(token=TELEGRAM_BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
groq_client = Groq(api_key=GROQ_API_KEY)

# ============ ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ• ĞŸĞ ĞĞ•ĞšĞ¢Ğ« (ĞºĞ¾Ğ¼Ğ¼Ğ¸Ñ‚Ñ‹ + Ñ€ĞµĞ»Ğ¸Ğ·Ñ‹) ============
TRACKED_PROJECTS = [
    # Zapret Ğ¸ DPI-Ğ¾Ğ±Ñ…Ğ¾Ğ´
    {"owner": "bol-van", "repo": "zapret", "name": "ğŸ›  Zapret (original)", "priority": "high"},
    {"owner": "bol-van", "repo": "zapret2", "name": "ğŸ›  Zapret 2", "priority": "high"},
    {"owner": "ValdikSS", "repo": "GoodbyeDPI", "name": "ğŸ›  GoodbyeDPI", "priority": "high"},
    {"owner": "hufrea", "repo": "byedpi", "name": "ğŸ›  ByeDPI", "priority": "high"},
    {"owner": "xvzc", "repo": "SpoofDPI", "name": "ğŸ›  SpoofDPI", "priority": "high"},
    
    # VPN Ğ¸ Ğ¿Ñ€Ğ¾ĞºÑĞ¸
    {"owner": "amnezia-vpn", "repo": "amnezia-client", "name": "ğŸ›¡ Amnezia Client", "priority": "high"},
    {"owner": "amnezia-vpn", "repo": "amneziawg-linux-kernel-module", "name": "ğŸ›¡ AmneziaWG Kernel", "priority": "medium"},
    {"owner": "XTLS", "repo": "Xray-core", "name": "âš¡ Xray-core", "priority": "high"},
    {"owner": "SagerNet", "repo": "sing-box", "name": "ğŸ“¦ Sing-Box", "priority": "high"},
    {"owner": "apernet", "repo": "hysteria", "name": "ğŸš€ Hysteria", "priority": "high"},
    {"owner": "Jigsaw-Code", "repo": "outline-server", "name": "ğŸ“¡ Outline Server", "priority": "medium"},
    {"owner": "Jigsaw-Code", "repo": "outline-client", "name": "ğŸ“¡ Outline Client", "priority": "medium"},
    
    # ĞŸĞ°Ğ½ĞµĞ»Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
    {"owner": "Gozargah", "repo": "Marzban", "name": "ğŸ› Marzban", "priority": "high"},
    {"owner": "MHSanaei", "repo": "3x-ui", "name": "ğŸ› 3X-UI", "priority": "high"},
    {"owner": "hiddify", "repo": "hiddify-next", "name": "ğŸ› Hiddify Next", "priority": "high"},
    {"owner": "hiddify", "repo": "Hiddify-Manager", "name": "ğŸ› Hiddify Manager", "priority": "medium"},
    
    # ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹
    {"owner": "MatsuriDayo", "repo": "nekoray", "name": "ğŸ± Nekoray", "priority": "high"},
    {"owner": "2dust", "repo": "v2rayN", "name": "ğŸ’» V2RayN", "priority": "high"},
    {"owner": "2dust", "repo": "v2rayNG", "name": "ğŸ“± V2RayNG", "priority": "high"},
    {"owner": "metacubex", "repo": "ClashMeta", "name": "âš”ï¸ Clash Meta", "priority": "medium"},
    {"owner": "metacubex", "repo": "mihomo", "name": "âš”ï¸ Mihomo", "priority": "medium"},
    
    # AntiZapret Ğ¸ ÑĞ¿Ğ¸ÑĞºĞ¸
    {"owner": "AntiZapret", "repo": "antizapret", "name": "ğŸ›¡ AntiZapret", "priority": "high"},
    {"owner": "AntiZapret", "repo": "antizapret-pac-generator-light", "name": "ğŸ›¡ AntiZapret PAC", "priority": "medium"},
    {"owner": "zapret-info", "repo": "z-i", "name": "ğŸ“‹ Zapret-Info", "priority": "medium"},
    {"owner": "C24Be", "repo": "AS_REG", "name": "ğŸ“‹ AS Registry RU", "priority": "medium"},
    
    # Ğ Ğ¾ÑĞºĞ¾Ğ¼ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ°
    {"owner": "roskomsvoboda", "repo": "censortracker", "name": "ğŸ“¢ CensorTracker", "priority": "high"},
    {"owner": "roskomsvoboda", "repo": "moscow_covid_queues", "name": "ğŸ“¢ RKS Tools", "priority": "low"},
]

# ============ ĞĞ“Ğ Ğ•Ğ“ĞĞ¢ĞĞ Ğ« ĞšĞĞĞ¤Ğ˜Ğ“ĞĞ’ ============
CONFIG_AGGREGATORS = [
    {"owner": "Leon406", "repo": "SubCrawler", "name": "ğŸ“¡ SubCrawler"},
    {"owner": "peasoft", "repo": "NoMoreWalls", "name": "ğŸ“¡ NoMoreWalls"},
    {"owner": "barry-far", "repo": "V2ray-Configs", "name": "ğŸ“¡ V2ray-Configs"},
    {"owner": "mahdibland", "repo": "V2RayAggregator", "name": "ğŸ“¡ V2RayAggregator"},
    {"owner": "Pawdroid", "repo": "Free-servers", "name": "ğŸ“¡ Free-servers"},
    {"owner": "aiboboxx", "repo": "v2rayfree", "name": "ğŸ“¡ V2RayFree"},
]

# ============ ĞŸĞĞ˜Ğ¡ĞšĞĞ’Ğ«Ğ• Ğ—ĞĞŸĞ ĞĞ¡Ğ« ============
FRESH_SEARCHES = [
    {"name": "Zapret Tools", "title": "ğŸ›  Zapret Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹", "query": "zapret OR zapret-discord OR zapret-youtube", "priority": 10},
    {"name": "DPI Bypass", "title": "ğŸ›  DPI Bypass", "query": "dpi-bypass OR bypass-dpi OR nodpi", "priority": 10},
    {"name": "RKN Block", "title": "ğŸ‘ Ğ ĞšĞ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸", "query": "roskomnadzor OR rkn-block OR rkn-bypass", "priority": 10},
    {"name": "TSPU", "title": "ğŸ‘ Ğ¢Ğ¡ĞŸĞ£", "query": "tspu OR sorm OR russia-censorship", "priority": 9},
    {"name": "AntiZapret", "title": "ğŸ›¡ AntiZapret", "query": "antizapret OR anti-zapret", "priority": 10},
    {"name": "Russia VPN", "title": "ğŸ”§ VPN Ğ´Ğ»Ñ Ğ Ğ¾ÑÑĞ¸Ğ¸", "query": "russia vpn OR russian-vpn OR vpn-russia", "priority": 8},
    {"name": "VLESS Reality", "title": "ğŸ”§ VLESS Reality", "query": "vless-reality OR reality-config", "priority": 8},
    {"name": "Hysteria2", "title": "ğŸš€ Hysteria 2", "query": "hysteria2 OR hysteria-2", "priority": 8},
    {"name": "XRay Config", "title": "âš¡ XRay ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸", "query": "xray-config OR xray-russia", "priority": 7},
    {"name": "Amnezia", "title": "ğŸ›¡ Amnezia", "query": "amnezia-vpn OR amneziawg", "priority": 9},
    {"name": "Marzban", "title": "ğŸ› Marzban", "query": "marzban-panel OR marzban-node", "priority": 8},
    {"name": "Geosite RU", "title": "ğŸ—º Geosite Russia", "query": "geosite-russia OR geoip-russia", "priority": 7},
    {"name": "Domain List RU", "title": "ğŸ“‹ Ğ¡Ğ¿Ğ¸ÑĞºĞ¸ Ğ´Ğ¾Ğ¼ĞµĞ½Ğ¾Ğ²", "query": "russia-domains OR ru-blocked-domains", "priority": 7},
    {"name": "Proxy Configs", "title": "ğŸ“¡ ĞŸÑ€Ğ¾ĞºÑĞ¸ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸", "query": "proxy-config-russia OR free-proxy-russia", "priority": 6},
    {"name": "Sing-Box RU", "title": "ğŸ“¦ Sing-Box", "query": "sing-box-russia OR singbox-config", "priority": 7},
    {"name": "Clash Rules", "title": "âš”ï¸ Clash Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°", "query": "clash-rules-russia OR clash-meta-russia", "priority": 6},
    {"name": "Shadowsocks", "title": "ğŸ” Shadowsocks", "query": "shadowsocks-russia OR ss-config", "priority": 6},
    {"name": "WireGuard RU", "title": "ğŸ”’ WireGuard", "query": "wireguard-russia OR wg-config-russia", "priority": 6},
    {"name": "Outline", "title": "ğŸ“¡ Outline", "query": "outline-russia OR outline-config", "priority": 6},
    {"name": "Censorship", "title": "ğŸŒ ĞĞ½Ñ‚Ğ¸Ñ†ĞµĞ½Ğ·ÑƒÑ€Ğ°", "query": "anti-censorship russia OR internet-freedom russia", "priority": 7},
]

FRESH_SEARCHES.sort(key=lambda x: x.get('priority', 5), reverse=True)

# ============ VALIDATION ============

def validate_env():
    required = {
        "GROQ_API_KEY": GROQ_API_KEY,
        "TELEGRAM_BOT_TOKEN": TELEGRAM_BOT_TOKEN,
        "CHANNEL_ID": TARGET_CHANNEL_ID,
        "GITHUB_TOKEN": GITHUB_TOKEN
    }
    
    missing = [k for k, v in required.items() if not v]
    
    if missing:
        logger.error(f"âŒ Missing environment variables: {', '.join(missing)}")
        return False
    
    logger.info("âœ… All environment variables validated")
    return True

def check_rate_limit():
    try:
        resp = requests.get("https://api.github.com/rate_limit", headers=API_HEADERS, timeout=10)
        if resp.status_code == 200:
            data = resp.json()
            remaining = data['rate']['remaining']
            limit = data['rate']['limit']
            
            logger.info(f"ğŸ“Š GitHub API: {remaining}/{limit} calls remaining")
            
            if remaining < MIN_API_CALLS_REMAINING:
                logger.warning(f"âš ï¸ API limit low ({remaining} left)")
                if remaining < 10:
                    return False
            return True
    except Exception as e:
        logger.warning(f"âš ï¸ Could not check rate limit: {e}")
    return True

# ============ HELPERS ============

def has_non_latin(text):
    if not text: 
        return False
    patterns = [
        r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff\uac00-\ud7af]',
        r'[\u0600-\u06ff\u0750-\u077f\uFB50-\uFDFF\uFE70-\uFEFF]',
        r'[\u0e00-\u0e7f\u1780-\u17ff]',
    ]
    return any(re.search(p, text) for p in patterns)

def get_age_hours(date_string):
    try:
        if not date_string: 
            return 9999
        dt = datetime.fromisoformat(date_string.replace('Z', '+00:00'))
        return (datetime.now(timezone.utc) - dt).total_seconds() / 3600
    except: 
        return 9999

def get_freshness(date_string):
    hours = get_age_hours(date_string)
    if hours < 1: return "ğŸ”¥ Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾"
    elif hours < 6: return f"ğŸ”¥ {int(hours)}Ñ‡ Ğ½Ğ°Ğ·Ğ°Ğ´"
    elif hours < 24: return "ğŸ”¥ Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½Ñ"
    elif hours < 48: return "âœ… Ğ’Ñ‡ĞµÑ€Ğ°"
    elif hours < 72: return "ğŸ“… 2 Ğ´Ğ½Ñ Ğ½Ğ°Ğ·Ğ°Ğ´"
    else: return f"ğŸ“… {int(hours/24)}Ğ´ Ğ½Ğ°Ğ·Ğ°Ğ´"

def is_fresh(date_string):
    return get_age_hours(date_string) <= (MAX_AGE_DAYS * 24)

def safe_desc(desc, max_len=120):
    if desc is None:
        return ""
    desc = str(desc).strip()
    desc = re.sub(r'[ğŸ”¥âš¡ï¸âœ¨ğŸ‰]{3,}', '', desc)
    return desc[:max_len] if desc else ""

def quick_filter(name, desc, stars=0):
    text = f"{name} {desc or ''}".lower()
    full_text = f"{name} {desc or ''}"

    if has_non_latin(full_text):
        return False

    if stars < MIN_STARS:
        return False

    whitelist = [
        'russia', 'russian', 'ru-', 'roskomnadzor', 'rkn', 'antizapret',
        'zapret', 'tspu', 'sorm', 'amnezia', 'hysteria', 'reality', 
        'marzban', 'xray', 'v2ray', 'vless', 'trojan', 'shadowsocks', 
        'clash', 'sing-box', 'bypass', 'proxy', 'vpn', 'dpi', 'gfw',
        'censorship', 'freedom', 'unblock'
    ]
    if any(w in text for w in whitelist):
        return True

    blacklist = [
        'china', 'chinese', 'cn-', 'iran', 'persian', 'vietnam',
        'homework', 'tutorial', 'example-', 'template', 'deprecated',
        'test-repo', 'demo-', 'practice', 'learning', 'course'
    ]
    if any(k in text for k in blacklist):
        return False

    return True

def is_likely_fork_spam(item):
    if not item.get('fork'):
        return False
    if item.get('stargazers_count', 0) == 0 and item.get('forks_count', 0) == 0:
        return True
    return False

# ============ GITHUB API FUNCTIONS ============

def get_latest_release(owner, repo):
    """âœ… ĞĞĞ’ĞĞ•: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ñ€ĞµĞ»Ğ¸Ğ·Ğ°"""
    url = f"https://api.github.com/repos/{owner}/{repo}/releases/latest"
    try:
        resp = requests.get(url, headers=API_HEADERS, timeout=10)
        if resp.status_code == 200:
            r = resp.json()
            return {
                "tag": r.get('tag_name', ''),
                "name": r.get('name', r.get('tag_name', '')),
                "date": r.get('published_at', r.get('created_at')),
                "url": r.get('html_url', ''),
                "body": (r.get('body', '') or '')[:300],
                "prerelease": r.get('prerelease', False)
            }
        elif resp.status_code == 404:
            logger.debug(f"   No releases for {owner}/{repo}")
    except Exception as e:
        logger.debug(f"Error getting release for {owner}/{repo}: {e}")
    return None

def get_recent_releases(owner, repo, limit=5):
    """âœ… ĞĞĞ’ĞĞ•: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… Ñ€ĞµĞ»Ğ¸Ğ·Ğ¾Ğ²"""
    url = f"https://api.github.com/repos/{owner}/{repo}/releases?per_page={limit}"
    try:
        resp = requests.get(url, headers=API_HEADERS, timeout=10)
        if resp.status_code == 200:
            releases = []
            for r in resp.json():
                if is_fresh(r.get('published_at', r.get('created_at'))):
                    releases.append({
                        "tag": r.get('tag_name', ''),
                        "name": r.get('name', r.get('tag_name', '')),
                        "date": r.get('published_at', r.get('created_at')),
                        "url": r.get('html_url', ''),
                        "body": (r.get('body', '') or '')[:300],
                        "prerelease": r.get('prerelease', False)
                    })
            return releases
    except Exception as e:
        logger.debug(f"Error getting releases for {owner}/{repo}: {e}")
    return []

def get_last_commit(owner, repo):
    url = f"https://api.github.com/repos/{owner}/{repo}/commits?per_page=1"
    try:
        resp = requests.get(url, headers=API_HEADERS, timeout=10)
        if resp.status_code == 200 and resp.json():
            c = resp.json()[0]
            msg = c['commit']['message'].split('\n')[0][:60]
            
            if has_non_latin(msg):
                return None
            
            return {
                "sha": c['sha'][:7],
                "date": c['commit']['committer']['date'],
                "msg": msg,
                "url": c['html_url']
            }
    except Exception as e:
        logger.debug(f"Error getting commit for {owner}/{repo}: {e}")
    return None

def search_fresh_repos(query, per_page=40):
    date_filter = (datetime.now(timezone.utc) - timedelta(days=MAX_AGE_DAYS)).strftime('%Y-%m-%d')
    
    results = []
    seen_ids = set()
    
    strategies = [
        f"{query}+pushed:>{date_filter}",
        f"{query}+created:>{date_filter}",
    ]
    
    for strategy in strategies:
        url = (
            f"https://api.github.com/search/repositories"
            f"?q={strategy}&sort=updated&order=desc&per_page={per_page}"
        )
        
        try:
            resp = requests.get(url, headers=API_HEADERS, timeout=15)
            if resp.status_code == 200:
                for item in resp.json().get('items', []):
                    if item['id'] not in seen_ids:
                        seen_ids.add(item['id'])
                        if is_fresh(item.get('pushed_at')) or is_fresh(item.get('updated_at')):
                            results.append(item)
            elif resp.status_code == 403:
                logger.warning("âš ï¸ GitHub API rate limit!")
                break
        except Exception as e:
            logger.warning(f"âš ï¸ Search error: {e}")
    
    return results

# ============ STATE MANAGEMENT ============

def load_state():
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, "r", encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"ğŸ“‚ Loaded: {len(data.get('posted', []))} posted, {len(data.get('releases', {}))} releases tracked")
                return data
        except Exception as e:
            logger.warning(f"Could not load state: {e}")
    return {"posted": [], "commits": {}, "releases": {}, "repo_cache": {}, "last_run": None}

def save_state(state):
    state['last_run'] = datetime.now(timezone.utc).isoformat()
    try:
        with open(STATE_FILE, "w", encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        logger.info(f"ğŸ’¾ State saved")
    except Exception as e:
        logger.error(f"âŒ Could not save state: {e}")

# ============ AI FUNCTIONS ============

async def analyze_relevance(repos):
    if not repos: 
        return {}

    text = "\n".join([
        f"{i+1}. {r['full_name']} | â­{r['stargazers_count']} | {safe_desc(r['description'], 80)}" 
        for i, r in enumerate(repos)
    ])

    prompt = f"""ĞÑ‚Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞ¹ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ´Ğ»Ñ ĞºĞ°Ğ½Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾ Ğ¾Ğ±Ñ…Ğ¾Ğ´ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ¾Ğº Ğ² Ğ Ğ¤.

Ğ¢ĞµĞ¼Ñ‹: VPN, Ğ¿Ñ€Ğ¾ĞºÑĞ¸, DPI-Ğ¾Ğ±Ñ…Ğ¾Ğ´, Zapret, ByeDPI, Amnezia, Ğ ĞšĞ, Ğ¢Ğ¡ĞŸĞ£, ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸, ÑĞ¿Ğ¸ÑĞºĞ¸ IP/Ğ´Ğ¾Ğ¼ĞµĞ½Ğ¾Ğ².

Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸:
{text}

ĞÑ‚Ğ²ĞµÑ‚ÑŒ GOOD Ğ¸Ğ»Ğ¸ SKIP Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾:
- GOOD: Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚/ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ°
- SKIP: Ğ¼ÑƒÑĞ¾Ñ€, ÑƒÑ‡ĞµĞ±Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚, Ğ½Ğµ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚:
1: GOOD
2: SKIP
..."""

    try:
        resp = groq_client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.1
        )
        
        res = {}
        for line in resp.choices[0].message.content.split('\n'):
            if ':' in line:
                try:
                    idx, verdict = line.split(':', 1)
                    idx = int(idx.strip().replace('.', ''))
                    res[idx] = 'GOOD' in verdict.upper()
                except: 
                    pass
        return res
    except Exception as e:
        logger.warning(f"âš ï¸ AI error: {e}")
        return {i: True for i in range(1, len(repos) + 1)}

async def generate_desc(name, desc):
    if desc and len(desc) > 25 and not has_non_latin(desc): 
        return desc

    prompt = f"""Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹: {name}
ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {desc or 'Ğ½ĞµÑ‚'}

ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ (1 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ, Ğ´Ğ¾ 80 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²) Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼.
ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: VPN, Ğ¾Ğ±Ñ…Ğ¾Ğ´ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ¾Ğº.

ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ:"""

    try:
        resp = groq_client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=60,
            temperature=0.3
        )
        generated = resp.choices[0].message.content.strip()
        if generated and not has_non_latin(generated):
            return generated
    except:
        pass
    
    return "Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ° Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ¾Ğº"

# ============ TELEGRAM ============

async def send_message_safe(chat_id, text):
    if has_non_latin(text):
        logger.warning("âš ï¸ Blocked message with hieroglyphs!")
        return False
    
    for attempt in range(3):
        try:
            await bot.send_message(chat_id, text, disable_web_page_preview=True)
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ Send attempt {attempt+1} failed: {e}")
            await asyncio.sleep(2 ** attempt)
    return False

# ============ POST BUILDERS ============

def build_release_post(project_name, release, owner, repo):
    """âœ… ĞŸĞ¾ÑÑ‚ Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ñ€ĞµĞ»Ğ¸Ğ·Ğµ"""
    tag = release['tag']
    name = release['name'] or tag
    body = release['body']
    
    # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° body
    if body:
        body = re.sub(r'#{1,6}\s*', '', body)  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ markdown Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸
        body = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', body)  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ bold/italic
        body = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', body)  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸
        body = body[:200] + ('...' if len(body) > 200 else '')
    
    text = (
        f"ğŸš€ <b>ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ»Ğ¸Ğ·: {html.escape(project_name)}</b>\n\n"
        f"ğŸ“¦ <code>{owner}/{repo}</code>\n"
        f"ğŸ· Ğ’ĞµÑ€ÑĞ¸Ñ: <b>{html.escape(tag)}</b>\n"
        f"â° {get_freshness(release['date'])}\n"
    )
    
    if body:
        text += f"\nğŸ“ {html.escape(body)}\n"
    
    text += f"\nğŸ”— <a href='{release['url']}'>Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ€ĞµĞ»Ğ¸Ğ·</a>"
    
    return text

def build_commit_post(project_name, commit, owner, repo):
    """ĞŸĞ¾ÑÑ‚ Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ¼ ĞºĞ¾Ğ¼Ğ¼Ğ¸Ñ‚Ğµ"""
    return (
        f"ğŸ”„ <b>{html.escape(project_name)}</b>\n\n"
        f"ğŸ“¦ <code>{owner}/{repo}</code>\n"
        f"â° {get_freshness(commit['date'])}\n"
        f"ğŸ“ <code>{html.escape(commit['msg'])}</code>\n\n"
        f"ğŸ”— <a href='{commit['url']}'>ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ ĞºĞ¾Ğ¼Ğ¼Ğ¸Ñ‚</a>"
    )

def build_repo_post(title, repo_full_name, stars, freshness, description, url):
    """ĞŸĞ¾ÑÑ‚ Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸"""
    return (
        f"<b>{title}</b>\n\n"
        f"ğŸ“¦ <code>{html.escape(repo_full_name)}</code>\n"
        f"â­ï¸ {stars} | â° {freshness}\n"
        f"ğŸ’¡ {html.escape(description)}\n\n"
        f"ğŸ”— <a href='{url}'>ĞÑ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ½Ğ° GitHub</a>"
    )

# ============ MAIN ============

async def main():
    logger.info("=" * 60)
    logger.info("ğŸ•µï¸  SCOUT RADAR v8.0 (with releases tracking)")
    logger.info("=" * 60)

    if not validate_env():
        return

    if not check_rate_limit():
        logger.error("âŒ Insufficient API calls. Exiting.")
        return

    state = load_state()
    posted = set(state.get("posted", []))
    commits = state.get("commits", {})
    releases = state.get("releases", {})
    repo_cache = state.get("repo_cache", {})
    count = 0

    # ============ 1. ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ Ğ•Ğ›Ğ˜Ğ—ĞĞ’ ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ¥ ĞŸĞ ĞĞ•ĞšĞ¢ĞĞ’ ============
    logger.info("\nğŸš€ Checking releases of tracked projects...")
    
    for project in TRACKED_PROJECTS:
        if count >= MAX_POSTS_PER_RUN:
            break
        
        owner = project['owner']
        repo = project['repo']
        key = f"{owner}/{repo}"
        
        fresh_releases = get_recent_releases(owner, repo)
        
        if not fresh_releases:
            continue
        
        for rel in fresh_releases:
            if count >= MAX_POSTS_PER_RUN:
                break
            
            release_key = f"{key}:{rel['tag']}"
            
            if release_key in releases:
                continue
            
            logger.info(f"   ğŸ†• Release: {project['name']} {rel['tag']}")
            
            success = await send_message_safe(
                TARGET_CHANNEL_ID,
                build_release_post(project['name'], rel, owner, repo)
            )
            
            if success:
                releases[release_key] = rel['date']
                count += 1
                await asyncio.sleep(MESSAGE_DELAY)

    # ============ 2. ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞšĞĞœĞœĞ˜Ğ¢ĞĞ’ ĞšĞ›Ğ®Ğ§Ğ•Ğ’Ğ«Ğ¥ ĞŸĞ ĞĞ•ĞšĞ¢ĞĞ’ ============
    logger.info("\nğŸ”„ Checking commits of tracked projects...")
    
    for project in TRACKED_PROJECTS:
        if count >= MAX_POSTS_PER_RUN:
            break
        
        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹ Ñ Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¼ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ¾Ğ¼ ĞµÑĞ»Ğ¸ ÑƒĞ¶Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ²
        if project.get('priority') == 'low' and count > MAX_POSTS_PER_RUN // 2:
            continue
        
        owner = project['owner']
        repo = project['repo']
        key = f"{owner}/{repo}"
        
        commit = get_last_commit(owner, repo)
        
        if not commit:
            continue
        
        if not is_fresh(commit['date']):
            continue
        
        if commits.get(key) == commit['sha']:
            continue
        
        logger.info(f"   ğŸ†• Commit: {project['name']}")
        
        success = await send_message_safe(
            TARGET_CHANNEL_ID,
            build_commit_post(project['name'], commit, owner, repo)
        )
        
        if success:
            commits[key] = commit['sha']
            count += 1
            await asyncio.sleep(MESSAGE_DELAY)

    # ============ 3. ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞ“Ğ Ğ•Ğ“ĞĞ¢ĞĞ ĞĞ’ ĞšĞĞĞ¤Ğ˜Ğ“ĞĞ’ ============
    logger.info("\nğŸ“¡ Checking config aggregators...")
    
    for agg in CONFIG_AGGREGATORS:
        if count >= MAX_POSTS_PER_RUN:
            break
        
        owner = agg['owner']
        repo = agg['repo']
        key = f"{owner}/{repo}"
        
        commit = get_last_commit(owner, repo)
        
        if not commit or not is_fresh(commit['date']):
            continue
        
        if commits.get(key) == commit['sha']:
            continue
        
        logger.info(f"   ğŸ†• {agg['name']}")
        
        success = await send_message_safe(
            TARGET_CHANNEL_ID,
            build_commit_post(agg['name'], commit, owner, repo)
        )
        
        if success:
            commits[key] = commit['sha']
            count += 1
            await asyncio.sleep(MESSAGE_DELAY)

    # ============ 4. ĞŸĞĞ˜Ğ¡Ğš ĞĞĞ’Ğ«Ğ¥ Ğ Ğ•ĞŸĞĞ—Ğ˜Ğ¢ĞĞ Ğ˜Ğ•Ğ’ ============
    logger.info("\nğŸ” Searching for new repositories...")
    
    for s in FRESH_SEARCHES:
        if count >= MAX_POSTS_PER_RUN:
            break
        
        if not check_rate_limit():
            break
        
        logger.info(f"\nğŸ” {s['name']}...")
        items = search_fresh_repos(s['query'])
        
        if not items:
            continue
        
        candidates = []
        for i in items:
            repo_id = str(i['id'])
            
            if repo_id in posted:
                continue
            
            if not quick_filter(i.get('full_name'), i.get('description'), i.get('stargazers_count', 0)):
                continue
            
            if is_likely_fork_spam(i):
                continue
            
            candidates.append(i)
        
        if not candidates:
            continue
        
        # AI Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸
        batch_size = 5
        for batch_start in range(0, len(candidates), batch_size):
            if count >= MAX_POSTS_PER_RUN:
                break
            
            batch = candidates[batch_start:batch_start + batch_size]
            decisions = await analyze_relevance(batch)
            
            for idx, item in enumerate(batch, 1):
                if count >= MAX_POSTS_PER_RUN:
                    break
                
                if not decisions.get(idx, False):
                    continue
                
                final_desc = await generate_desc(item['full_name'], item['description'])
                
                success = await send_message_safe(
                    TARGET_CHANNEL_ID,
                    build_repo_post(
                        s.get('title', s['name']),
                        item['full_name'],
                        item['stargazers_count'],
                        get_freshness(item['pushed_at']),
                        final_desc,
                        item['html_url']
                    )
                )
                
                if success:
                    posted.add(str(item['id']))
                    count += 1
                    logger.info(f"   âœ… {item['full_name']}")
                    await asyncio.sleep(MESSAGE_DELAY)
            
            await asyncio.sleep(GROQ_DELAY)

    # ============ SAVE STATE ============
    save_state({
        "posted": list(posted)[-3000:],
        "commits": commits,
        "releases": releases,
        "repo_cache": repo_cache
    })
    
    logger.info(f"\n{'=' * 60}")
    logger.info(f"ğŸ Completed! Published: {count} posts")
    logger.info(f"{'=' * 60}")
    
    await bot.session.close()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\nâ¸ Interrupted by user")
    except Exception as e:
        logger.error(f"âŒ Fatal error: {e}", exc_info=True)
